# JAR-A2A: Comunicaci贸n Multiagente Soberana con Protocolos MCP y A2A

Este repositorio contiene la implementaci贸n de un sistema de comunicaci贸n multiagente basado en modelos de lenguaje (LLM), construido como prueba de concepto del **protocolo JAR-A2A** (Any-to-Any). El sistema integra dos protocolos inspirados en la literatura reciente: **MCP (Model Context Protocol)** y **A2A**, con un dise帽o modular preparado para su integraci贸n futura con marcos de identidad soberana y espacios de datos federados.

##  Prop贸sito del Proyecto

Este trabajo se enmarca en un proyecto de investigaci贸n centrado en la intersecci贸n entre:

- Comunicaci贸n entre agentes inteligentes distribuidos
- Acceso soberano a datos en entornos federados (Data Spaces)
- Est谩ndares emergentes como **Google A2A** y **Gaia-X Trust Framework**

El objetivo principal es ofrecer una arquitectura abierta y extensible para la mensajer铆a entre agentes aut贸nomos, compatible con principios de interoperabilidad, trazabilidad y control de identidad.

---

## П Estructura del Sistema

El sistema se compone de tres microservicios principales:

- **LLM Agent**: Genera consultas SQL a partir de preguntas en lenguaje natural.
- **MCP Server**: Act煤a como broker, registrador y pasarela de acceso a la base de datos.
- **Ventas Agent**: Ejecuta consultas SQL y devuelve resultados estructurados.
- - И **DuckDB + Apache Iceberg**: se ha utilizado un lake-house local con la tabla `iceberg_space.ventas` que contiene:
  - `fecha` (DATE)
  - `producto` (TEXT)
  - `cantidad` (INTEGER)
  - `precio` (DOUBLE)

Todos los servicios se comunican utilizando el protocolo **JAR-A2A**, que extiende el modelo de envelopes definido por Google con mecanismos de control asincr贸nico, retransmisi贸n, discovery sem谩ntico y separaci贸n l贸gica de servicios.

---

## И Funcionalidades implementadas

- Registro din谩mico de agentes y descubrimiento por capacidades
- Confirmaci贸n de entrega (ACKs) y retransmisi贸n en caso de fallo
- Heartbeats peri贸dicos para supervisi贸n de disponibilidad
- Correlaci贸n de mensajes mediante `correlation_id`
- Exposici贸n de servicios contextualizados v铆a protocolo MCP
- Generaci贸n autom谩tica de SQL a partir de lenguaje natural con LLM local
- Comunicaci贸n A2A entre agentes mediante mensajes JSON estructurados

---

## 锔 Tecnolog铆as empleadas

- Python 3.11
- FastAPI
- Docker & Docker Compose
- DuckDB
- Apache Iceberg
- TinyLlama (modelo LLM local)
- JWT (explorado para futura integraci贸n de seguridad federada)

---

##  Despliegue local

El proyecto se despliega localmente mediante Docker Compose:

```bash
docker compose build
docker compose up
````
Para replicar las pruebas del flujo de comunicaci贸n realizadas durante la documentaci贸n del proyecto, se puede hacer uso del script cli.py:

```bash
python scripts/cli.py "Introduzca-consulta-al-LLM"
````

Aseg煤rate de que los puertos 8000, 8002 y 8003 est茅n libres. La interfaz de consulta est谩 expuesta en el puerto 8003 bajo el endpoint /query.

## Consideraciones de seguridad

Aunque el sistema no incorpora por defecto mecanismos criptogr谩ficos, ha sido dise帽ado para permitir en el futuro:

- Firma de mensajes (JWT + RS256)

- Identidad descentralizada (DID + Verifiable Credentials)

- Validaci贸n de pol铆ticas de autorizaci贸n y trazabilidad

  Puede consultarte la exploraci贸n a esta aproximaci贸n implementada en la rama **security**.
