# DocumentaciÃ³n del TFG: InterconexiÃ³n entre Espacios de Datos e Inteligencia Artificial Generativa

**Fecha**: 11/04/2025  
**Autor**: Jaime Alonso Ruiz
**Tutor**: JoaquÃ­n SalvachÃºa
**TÃ­tulo del TFG**: *DiseÃ±o e implementaciÃ³n de interconexiÃ³n entre espacios de datos e inteligencia artificial generativa*

---

## ğŸ¯ PropÃ³sito del proyecto

El objetivo principal de este Trabajo de Fin de Grado es diseÃ±ar e implementar una arquitectura funcional y escalable que permita a un modelo de lenguaje (LLM) interactuar con un espacio de datos utilizando el **Model Context Protocol (MCP)**.  
El cliente (el modelo de lenguaje) **no debe acceder directamente a la base de datos**, sino que todas las operaciones deben realizarse exclusivamente a travÃ©s del servidor MCP, que actÃºa como capa intermedia segura, modular y extensible.

---

## ğŸ§± Arquitectura actual

### Componentes principales:

- **ğŸ§  Cliente LLM (`cliente_llm.py`)**
  - Ejecuta preguntas en lenguaje natural.
  - Utiliza el modelo `TinyLlama-1.1B-Chat-v1.0`.
  - Genera consultas SQL a partir de preguntas.
  - Consulta datos exclusivamente a travÃ©s del servidor MCP.
  - Interpreta los resultados devueltos y construye una respuesta explicativa.
  - Registra todo el proceso en un log: `logs/cliente_llm.log`.

- **ğŸ”— Servidor MCP (`main.py`)**
  - Desarrollado en FastAPI.
  - Conectado a un espacio de datos local basado en DuckDB.
  - ExposiciÃ³n de herramientas MCP mediante endpoints REST:
    - `/tool/consulta`: ejecuta una consulta SQL.
    - `/tool/info/productos`: devuelve la lista de productos distintos.
    - `/tool/info/fechas`: devuelve el rango mÃ­nimo y mÃ¡ximo de fechas registradas.

- **ğŸ“‚ Espacio de datos**
  - Implementado localmente usando DuckDB (`lake.duckdb`).
  - Contiene una tabla `iceberg_space.ventas` con las siguientes columnas:
    - `fecha` (DATE)
    - `producto` (TEXT)
    - `cantidad` (INTEGER)
    - `precio` (DOUBLE)
  - Los datos se cargan desde `load_data.py`.

---

## ğŸ”’ Principios y decisiones clave

- âœ… SeparaciÃ³n estricta entre procesamiento semÃ¡ntico (LLM) y acceso a datos (MCP).
- âœ… Cumplimiento del diseÃ±o propuesto por MCP: los LLMs acceden a los datos solo a travÃ©s de herramientas ("tools").
- âœ… Uso de prompts enriquecidos con informaciÃ³n contextual previa obtenida del MCP.
- âœ… Arquitectura modular, extensible y trazable mediante logs.

---

## ğŸ“ˆ Escalabilidad futura

El diseÃ±o actual se ha planteado desde el principio con una visiÃ³n clara de crecimiento:

- ğŸ” SustituciÃ³n futura de DuckDB por Apache Iceberg real o incluso Trino/Presto.
- ğŸ¤– SustituciÃ³n del modelo TinyLlama por un LLM mÃ¡s avanzado o alojado en GPU.
- ğŸ” EvoluciÃ³n hacia una arquitectura RAG (Retrieval-Augmented Generation), donde:
  - El LLM consulta primero un vector store basado en embeddings generados desde el MCP.
  - El contenido recuperado se pasa como contexto al modelo para respuestas mÃ¡s precisas.

AdemÃ¡s, se podrÃ¡n incorporar nuevas herramientas MCP como:

- `/tool/info/esquema`
- `/tool/info/documentacion`
- `/tool/descargar`
- `/tool/upload-pdf`

---

## ğŸ“œ ConclusiÃ³n

Se ha establecido una base sÃ³lida, funcional y alineada con las exigencias del TFG.  
El sistema ya permite una interacciÃ³n completa entre un modelo de lenguaje y un espacio de datos, cumpliendo con los principios del MCP y dejando preparado el camino para su futura evoluciÃ³n hacia un sistema RAG mÃ¡s avanzado.

